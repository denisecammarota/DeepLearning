{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import models as models\n",
    "import activations as activations\n",
    "import optimizers as optimizers\n",
    "import losses as losses\n",
    "import metrics as metrics\n",
    "import layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "training data:  1.7332857667211956 0.25\n",
      "epoch: 1\n",
      "training data:  1.5680517032987475 0.0\n",
      "epoch: 2\n",
      "training data:  1.3509215514439177 0.0\n",
      "epoch: 3\n",
      "training data:  1.0795404514640752 0.0\n",
      "epoch: 4\n",
      "training data:  0.8431946399308574 0.0\n",
      "epoch: 5\n",
      "training data:  0.7257560308979878 0.0\n",
      "epoch: 6\n",
      "training data:  0.6675705013448114 0.0\n",
      "epoch: 7\n",
      "training data:  0.619313368908915 0.0\n",
      "epoch: 8\n",
      "training data:  0.5718648758386016 0.0\n",
      "epoch: 9\n",
      "training data:  0.5249892290387588 0.0\n",
      "epoch: 10\n",
      "training data:  0.47967801838625257 0.0\n",
      "epoch: 11\n",
      "training data:  0.4368731510329269 0.0\n",
      "epoch: 12\n",
      "training data:  0.39720310622491295 0.0\n",
      "epoch: 13\n",
      "training data:  0.36097026516082986 0.0\n",
      "epoch: 14\n",
      "training data:  0.32822426565194 0.0\n",
      "epoch: 15\n",
      "training data:  0.2988472258783069 0.0\n",
      "epoch: 16\n",
      "training data:  0.27262236428386477 0.0\n",
      "epoch: 17\n",
      "training data:  0.24928236925088593 0.0\n",
      "epoch: 18\n",
      "training data:  0.22854165952551164 0.0\n",
      "epoch: 19\n",
      "training data:  0.21011706437752697 0.0\n",
      "epoch: 20\n",
      "training data:  0.1937403235018306 0.0\n",
      "epoch: 21\n",
      "training data:  0.17916487672014614 0.0\n",
      "epoch: 22\n",
      "training data:  0.16616878537395743 0.0\n",
      "epoch: 23\n",
      "training data:  0.15455515899484526 0.0\n",
      "epoch: 24\n",
      "training data:  0.14415108171671998 0.0\n",
      "epoch: 25\n",
      "training data:  0.13480572742556146 0.0\n",
      "epoch: 26\n",
      "training data:  0.126388117793954 0.0\n",
      "epoch: 27\n",
      "training data:  0.1187848063453994 0.0\n",
      "epoch: 28\n",
      "training data:  0.11189765332230156 0.0\n",
      "epoch: 29\n",
      "training data:  0.10564177789223583 0.0\n",
      "epoch: 30\n",
      "training data:  0.09994372479646442 0.0\n",
      "epoch: 31\n",
      "training data:  0.09473985283657503 0.0\n",
      "epoch: 32\n",
      "training data:  0.08997493586563723 0.0\n",
      "epoch: 33\n",
      "training data:  0.08560095845693333 0.0\n",
      "epoch: 34\n",
      "training data:  0.08157608496259705 0.0\n",
      "epoch: 35\n",
      "training data:  0.07786378015149288 0.0\n",
      "epoch: 36\n",
      "training data:  0.07443206069965767 0.0\n",
      "epoch: 37\n",
      "training data:  0.07125285867669286 0.0\n",
      "epoch: 38\n",
      "training data:  0.06830148033807677 0.0\n",
      "epoch: 39\n",
      "training data:  0.06555614571734143 0.0\n",
      "epoch: 40\n",
      "training data:  0.06299759656492213 0.0\n",
      "epoch: 41\n",
      "training data:  0.06060876203269697 0.0\n",
      "epoch: 42\n",
      "training data:  0.05837447313150365 0.0\n",
      "epoch: 43\n",
      "training data:  0.05628121839574139 0.0\n",
      "epoch: 44\n",
      "training data:  0.05431693439037097 0.0\n",
      "epoch: 45\n",
      "training data:  0.052470825712963375 0.0\n",
      "epoch: 46\n",
      "training data:  0.050733210000254984 0.0\n",
      "epoch: 47\n",
      "training data:  0.04909538416761548 0.0\n",
      "epoch: 48\n",
      "training data:  0.047549508711664 0.0\n",
      "epoch: 49\n",
      "training data:  0.04608850740940165 0.0\n",
      "epoch: 50\n",
      "training data:  0.04470598016760665 0.0\n",
      "epoch: 51\n",
      "training data:  0.043396127127497054 0.0\n",
      "epoch: 52\n",
      "training data:  0.042153682423311634 0.0\n",
      "epoch: 53\n",
      "training data:  0.04097385623916518 0.0\n",
      "epoch: 54\n",
      "training data:  0.039852284014355796 0.0\n",
      "epoch: 55\n",
      "training data:  0.03878498181995588 0.0\n",
      "epoch: 56\n",
      "training data:  0.0377683070745707 0.0\n",
      "epoch: 57\n",
      "training data:  0.03679892388921838 0.0\n",
      "epoch: 58\n",
      "training data:  0.03587377243419418 0.0\n",
      "epoch: 59\n",
      "training data:  0.03499004180770176 0.0\n",
      "epoch: 60\n",
      "training data:  0.03414514595958561 0.0\n",
      "epoch: 61\n",
      "training data:  0.03333670228586148 0.0\n",
      "epoch: 62\n",
      "training data:  0.03256251256272175 0.0\n",
      "epoch: 63\n",
      "training data:  0.03182054593378919 0.0\n",
      "epoch: 64\n",
      "training data:  0.031108923702857068 0.0\n",
      "epoch: 65\n",
      "training data:  0.030425905717225026 0.0\n",
      "epoch: 66\n",
      "training data:  0.029769878154888667 0.0\n",
      "epoch: 67\n",
      "training data:  0.029139342552990007 0.0\n",
      "epoch: 68\n",
      "training data:  0.028532905935697607 0.0\n",
      "epoch: 69\n",
      "training data:  0.027949271917565216 0.0\n",
      "epoch: 70\n",
      "training data:  0.02738723267384855 0.0\n",
      "epoch: 71\n",
      "training data:  0.026845661682599442 0.0\n",
      "epoch: 72\n",
      "training data:  0.026323507154910754 0.0\n",
      "epoch: 73\n",
      "training data:  0.025819786079711846 0.0\n",
      "epoch: 74\n",
      "training data:  0.025333578818228876 0.0\n",
      "epoch: 75\n",
      "training data:  0.024864024190814207 0.0\n",
      "epoch: 76\n",
      "training data:  0.024410315005467687 0.0\n",
      "epoch: 77\n",
      "training data:  0.023971693983158918 0.0\n",
      "epoch: 78\n",
      "training data:  0.023547450040120273 0.0\n",
      "epoch: 79\n",
      "training data:  0.023136914891720345 0.0\n",
      "epoch: 80\n",
      "training data:  0.022739459946423506 0.0\n",
      "epoch: 81\n",
      "training data:  0.022354493461768977 0.0\n",
      "epoch: 82\n",
      "training data:  0.02198145793732178 0.0\n",
      "epoch: 83\n",
      "training data:  0.02161982772221064 0.0\n",
      "epoch: 84\n",
      "training data:  0.02126910681722082 0.0\n",
      "epoch: 85\n",
      "training data:  0.020928826853490935 0.0\n",
      "epoch: 86\n",
      "training data:  0.020598545231707684 0.0\n",
      "epoch: 87\n",
      "training data:  0.020277843407328026 0.0\n",
      "epoch: 88\n",
      "training data:  0.019966325308812444 0.0\n",
      "epoch: 89\n",
      "training data:  0.019663615877146122 0.0\n",
      "epoch: 90\n",
      "training data:  0.019369359716076995 0.0\n",
      "epoch: 91\n",
      "training data:  0.019083219843527652 0.0\n",
      "epoch: 92\n",
      "training data:  0.01880487653555518 0.0\n",
      "epoch: 93\n",
      "training data:  0.01853402625505462 0.0\n",
      "epoch: 94\n",
      "training data:  0.01827038065813614 0.0\n",
      "epoch: 95\n",
      "training data:  0.018013665671764642 0.0\n",
      "epoch: 96\n",
      "training data:  0.01776362063684179 0.0\n",
      "epoch: 97\n",
      "training data:  0.017519997511442006 0.0\n",
      "epoch: 98\n",
      "training data:  0.017282560129390556 0.0\n",
      "epoch: 99\n",
      "training data:  0.01705108350980378 0.0\n",
      "epoch: 100\n",
      "training data:  0.016825353213597342 0.0\n",
      "epoch: 101\n",
      "training data:  0.016605164743320456 0.0\n",
      "epoch: 102\n",
      "training data:  0.016390322982988155 0.0\n",
      "epoch: 103\n",
      "training data:  0.016180641674871283 0.0\n",
      "epoch: 104\n",
      "training data:  0.015975942930461624 0.0\n",
      "epoch: 105\n",
      "training data:  0.015776056773064498 0.0\n",
      "epoch: 106\n",
      "training data:  0.015580820709683705 0.0\n",
      "epoch: 107\n",
      "training data:  0.01539007933005727 0.0\n",
      "epoch: 108\n",
      "training data:  0.015203683930876816 0.0\n",
      "epoch: 109\n",
      "training data:  0.01502149216338451 0.0\n",
      "epoch: 110\n",
      "training data:  0.014843367702685337 0.0\n",
      "epoch: 111\n",
      "training data:  0.014669179937245855 0.0\n",
      "epoch: 112\n",
      "training data:  0.014498803677170947 0.0\n",
      "epoch: 113\n",
      "training data:  0.014332118879960332 0.0\n",
      "epoch: 114\n",
      "training data:  0.014169010392547043 0.0\n",
      "epoch: 115\n",
      "training data:  0.014009367708512712 0.0\n",
      "epoch: 116\n",
      "training data:  0.013853084739458007 0.5\n",
      "epoch: 117\n",
      "training data:  0.013700059599584287 0.5\n",
      "epoch: 118\n",
      "training data:  0.01355019440261284 0.5\n",
      "epoch: 119\n",
      "training data:  0.013403395070233002 0.5\n",
      "epoch: 120\n",
      "training data:  0.013259571151330335 0.5\n",
      "epoch: 121\n",
      "training data:  0.013118635651299768 0.5\n",
      "epoch: 122\n",
      "training data:  0.012980504870800182 0.5\n",
      "epoch: 123\n",
      "training data:  0.012845098253351835 0.5\n",
      "epoch: 124\n",
      "training data:  0.01271233824122143 0.5\n",
      "epoch: 125\n",
      "training data:  0.012582150139078704 0.5\n",
      "epoch: 126\n",
      "training data:  0.012454461984943984 0.5\n",
      "epoch: 127\n",
      "training data:  0.012329204427980538 0.5\n",
      "epoch: 128\n",
      "training data:  0.012206310612715139 0.5\n",
      "epoch: 129\n",
      "training data:  0.012085716069299549 0.5\n",
      "epoch: 130\n",
      "training data:  0.01196735860945171 0.5\n",
      "epoch: 131\n",
      "training data:  0.011851178227739307 0.5\n",
      "epoch: 132\n",
      "training data:  0.011737117007891602 0.5\n",
      "epoch: 133\n",
      "training data:  0.011625119033845431 0.5\n",
      "epoch: 134\n",
      "training data:  0.011515130305251278 0.5\n",
      "epoch: 135\n",
      "training data:  0.011407098657182807 0.5\n",
      "epoch: 136\n",
      "training data:  0.011300973683809945 0.5\n",
      "epoch: 137\n",
      "training data:  0.011196706665811055 0.5\n",
      "epoch: 138\n",
      "training data:  0.011094250501313992 0.5\n",
      "epoch: 139\n",
      "training data:  0.010993559640169133 0.5\n",
      "epoch: 140\n",
      "training data:  0.010894590021370009 0.5\n",
      "epoch: 141\n",
      "training data:  0.01079729901344827 0.5\n",
      "epoch: 142\n",
      "training data:  0.010701645357680907 0.5\n",
      "epoch: 143\n",
      "training data:  0.010607589113957287 0.5\n",
      "epoch: 144\n",
      "training data:  0.010515091609162957 0.5\n",
      "epoch: 145\n",
      "training data:  0.010424115387945887 0.5\n",
      "epoch: 146\n",
      "training data:  0.010334624165738916 0.5\n",
      "epoch: 147\n",
      "training data:  0.010246582783919376 0.5\n",
      "epoch: 148\n",
      "training data:  0.01015995716699456 0.5\n",
      "epoch: 149\n",
      "training data:  0.010074714281707657 0.5\n",
      "epoch: 150\n",
      "training data:  0.009990822097965228 0.5\n",
      "epoch: 151\n",
      "training data:  0.009908249551492977 0.5\n",
      "epoch: 152\n",
      "training data:  0.00982696650813201 0.5\n",
      "epoch: 153\n",
      "training data:  0.009746943729692738 0.5\n",
      "epoch: 154\n",
      "training data:  0.00966815284128831 0.5\n",
      "epoch: 155\n",
      "training data:  0.009590566300073778 0.5\n",
      "epoch: 156\n",
      "training data:  0.009514157365321777 0.5\n",
      "epoch: 157\n",
      "training data:  0.009438900069768556 0.5\n",
      "epoch: 158\n",
      "training data:  0.009364769192168712 0.5\n",
      "epoch: 159\n",
      "training data:  0.009291740230999913 0.5\n",
      "epoch: 160\n",
      "training data:  0.009219789379262102 0.5\n",
      "epoch: 161\n",
      "training data:  0.009148893500318828 0.5\n",
      "epoch: 162\n",
      "training data:  0.009079030104731232 0.5\n",
      "epoch: 163\n",
      "training data:  0.009010177328037643 0.5\n",
      "epoch: 164\n",
      "training data:  0.008942313909434368 0.5\n",
      "epoch: 165\n",
      "training data:  0.008875419171315858 0.5\n",
      "epoch: 166\n",
      "training data:  0.008809472999634024 0.5\n",
      "epoch: 167\n",
      "training data:  0.008744455825039297 0.5\n",
      "epoch: 168\n",
      "training data:  0.00868034860476742 0.5\n",
      "epoch: 169\n",
      "training data:  0.008617132805238127 0.5\n",
      "epoch: 170\n",
      "training data:  0.008554790385333511 0.5\n",
      "epoch: 171\n",
      "training data:  0.008493303780325449 0.5\n",
      "epoch: 172\n",
      "training data:  0.008432655886423123 0.5\n",
      "epoch: 173\n",
      "training data:  0.008372830045913196 0.5\n",
      "epoch: 174\n",
      "training data:  0.008313810032866282 0.5\n",
      "epoch: 175\n",
      "training data:  0.008255580039384983 0.5\n",
      "epoch: 176\n",
      "training data:  0.008198124662369893 0.5\n",
      "epoch: 177\n",
      "training data:  0.008141428890781005 0.5\n",
      "epoch: 178\n",
      "training data:  0.008085478093373257 0.5\n",
      "epoch: 179\n",
      "training data:  0.008030258006885803 0.5\n",
      "epoch: 180\n",
      "training data:  0.007975754724665754 0.5\n",
      "epoch: 181\n",
      "training data:  0.007921954685707996 0.5\n",
      "epoch: 182\n",
      "training data:  0.007868844664093362 0.5\n",
      "epoch: 183\n",
      "training data:  0.007816411758808829 0.75\n",
      "epoch: 184\n",
      "training data:  0.007764643383933449 0.75\n",
      "epoch: 185\n",
      "training data:  0.00771352725917516 0.75\n",
      "epoch: 186\n",
      "training data:  0.007663051400743799 1.0\n",
      "epoch: 187\n",
      "training data:  0.007613204112546797 1.0\n",
      "epoch: 188\n",
      "training data:  0.00756397397769415 1.0\n",
      "epoch: 189\n",
      "training data:  0.007515349850300359 1.0\n",
      "epoch: 190\n",
      "training data:  0.007467320847571211 1.0\n",
      "epoch: 191\n",
      "training data:  0.0074198763421641865 1.0\n",
      "epoch: 192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  0.007373005954811298 1.0\n",
      "epoch: 193\n",
      "training data:  0.007326699547194351 1.0\n",
      "epoch: 194\n",
      "training data:  0.007280947215062296 1.0\n",
      "epoch: 195\n",
      "training data:  0.007235739281581416 1.0\n",
      "epoch: 196\n",
      "training data:  0.007191066290909256 1.0\n",
      "epoch: 197\n",
      "training data:  0.007146919001983464 1.0\n",
      "epoch: 198\n",
      "training data:  0.0071032883825174415 1.0\n",
      "epoch: 199\n",
      "training data:  0.007060165603194763 1.0\n",
      "epoch: 200\n",
      "training data:  0.007017542032054819 1.0\n",
      "epoch: 201\n",
      "training data:  0.00697540922906228 1.0\n",
      "epoch: 202\n",
      "training data:  0.006933758940853751 1.0\n",
      "epoch: 203\n",
      "training data:  0.006892583095654573 1.0\n",
      "epoch: 204\n",
      "training data:  0.006851873798359716 1.0\n",
      "epoch: 205\n",
      "training data:  0.006811623325772467 1.0\n",
      "epoch: 206\n",
      "training data:  0.006771824121995172 1.0\n",
      "epoch: 207\n",
      "training data:  0.006732468793966415 1.0\n",
      "epoch: 208\n",
      "training data:  0.006693550107139215 1.0\n",
      "epoch: 209\n",
      "training data:  0.006655060981295181 1.0\n",
      "epoch: 210\n",
      "training data:  0.006616994486489596 1.0\n",
      "epoch: 211\n",
      "training data:  0.006579343839122815 1.0\n",
      "epoch: 212\n",
      "training data:  0.0065421023981333554 1.0\n",
      "epoch: 213\n",
      "training data:  0.006505263661308324 1.0\n",
      "epoch: 214\n",
      "training data:  0.006468821261707084 1.0\n",
      "epoch: 215\n",
      "training data:  0.006432768964194103 1.0\n",
      "epoch: 216\n",
      "training data:  0.006397100662077083 1.0\n",
      "epoch: 217\n",
      "training data:  0.006361810373846819 1.0\n",
      "epoch: 218\n",
      "training data:  0.00632689224001505 1.0\n",
      "epoch: 219\n",
      "training data:  0.006292340520047155 1.0\n",
      "epoch: 220\n",
      "training data:  0.006258149589386075 1.0\n",
      "epoch: 221\n",
      "training data:  0.006224313936564679 1.0\n",
      "epoch: 222\n",
      "training data:  0.006190828160403257 1.0\n",
      "epoch: 223\n",
      "training data:  0.006157686967289439 1.0\n",
      "epoch: 224\n",
      "training data:  0.006124885168537646 1.0\n",
      "epoch: 225\n",
      "training data:  0.006092417677825371 1.0\n",
      "epoch: 226\n",
      "training data:  0.0060602795087037805 1.0\n",
      "epoch: 227\n",
      "training data:  0.006028465772180119 1.0\n",
      "epoch: 228\n",
      "training data:  0.0059969716743694754 1.0\n",
      "epoch: 229\n",
      "training data:  0.0059657925142137256 1.0\n",
      "epoch: 230\n",
      "training data:  0.0059349236812652915 1.0\n",
      "epoch: 231\n",
      "training data:  0.005904360653533715 1.0\n",
      "epoch: 232\n",
      "training data:  0.0058740989953929065 1.0\n",
      "epoch: 233\n",
      "training data:  0.005844134355547171 1.0\n",
      "epoch: 234\n",
      "training data:  0.005814462465053993 1.0\n",
      "epoch: 235\n",
      "training data:  0.0057850791354018775 1.0\n",
      "epoch: 236\n",
      "training data:  0.005755980256641372 1.0\n",
      "epoch: 237\n",
      "training data:  0.00572716179556768 1.0\n",
      "epoch: 238\n",
      "training data:  0.00569861979395307 1.0\n",
      "epoch: 239\n",
      "training data:  0.005670350366827639 1.0\n",
      "epoch: 240\n",
      "training data:  0.005642349700806876 1.0\n",
      "epoch: 241\n",
      "training data:  0.005614614052464469 1.0\n",
      "epoch: 242\n",
      "training data:  0.0055871397467490876 1.0\n",
      "epoch: 243\n",
      "training data:  0.005559923175443574 1.0\n",
      "epoch: 244\n",
      "training data:  0.005532960795665462 1.0\n",
      "epoch: 245\n",
      "training data:  0.005506249128407313 1.0\n",
      "epoch: 246\n",
      "training data:  0.005479784757115853 1.0\n",
      "epoch: 247\n",
      "training data:  0.005453564326308555 1.0\n",
      "epoch: 248\n",
      "training data:  0.005427584540226599 1.0\n",
      "epoch: 249\n",
      "training data:  0.00540184216152315 1.0\n",
      "epoch: 250\n",
      "training data:  0.00537633400998579 1.0\n",
      "epoch: 251\n",
      "training data:  0.005351056961292096 1.0\n",
      "epoch: 252\n",
      "training data:  0.005326007945797499 1.0\n",
      "epoch: 253\n",
      "training data:  0.005301183947354208 1.0\n",
      "epoch: 254\n",
      "training data:  0.0052765820021605445 1.0\n",
      "epoch: 255\n",
      "training data:  0.005252199197639564 1.0\n",
      "epoch: 256\n",
      "training data:  0.005228032671346286 1.0\n",
      "epoch: 257\n",
      "training data:  0.005204079609902562 1.0\n",
      "epoch: 258\n",
      "training data:  0.005180337247958768 1.0\n",
      "epoch: 259\n",
      "training data:  0.005156802867181684 1.0\n",
      "epoch: 260\n",
      "training data:  0.005133473795267641 1.0\n",
      "epoch: 261\n",
      "training data:  0.00511034740498021 1.0\n",
      "epoch: 262\n",
      "training data:  0.00508742111321195 1.0\n",
      "epoch: 263\n",
      "training data:  0.005064692380069148 1.0\n",
      "epoch: 264\n",
      "training data:  0.005042158707979255 1.0\n",
      "epoch: 265\n",
      "training data:  0.005019817640820141 1.0\n",
      "epoch: 266\n",
      "training data:  0.004997666763070689 1.0\n",
      "epoch: 267\n",
      "training data:  0.004975703698981966 1.0\n",
      "epoch: 268\n",
      "training data:  0.004953926111768586 1.0\n",
      "epoch: 269\n",
      "training data:  0.004932331702819554 1.0\n",
      "epoch: 270\n",
      "training data:  0.004910918210928079 1.0\n",
      "epoch: 271\n",
      "training data:  0.004889683411539934 1.0\n",
      "epoch: 272\n",
      "training data:  0.004868625116019634 1.0\n",
      "epoch: 273\n",
      "training data:  0.004847741170934131 1.0\n",
      "epoch: 274\n",
      "training data:  0.004827029457353513 1.0\n",
      "epoch: 275\n",
      "training data:  0.004806487890168134 1.0\n",
      "epoch: 276\n",
      "training data:  0.00478611441742183 1.0\n",
      "epoch: 277\n",
      "training data:  0.004765907019660818 1.0\n",
      "epoch: 278\n",
      "training data:  0.004745863709297633 1.0\n",
      "epoch: 279\n",
      "training data:  0.004725982529990023 1.0\n",
      "epoch: 280\n",
      "training data:  0.004706261556034115 1.0\n",
      "epoch: 281\n",
      "training data:  0.00468669889177165 1.0\n",
      "epoch: 282\n",
      "training data:  0.004667292671010782 1.0\n",
      "epoch: 283\n",
      "training data:  0.004648041056460219 1.0\n",
      "epoch: 284\n",
      "training data:  0.004628942239176218 1.0\n",
      "epoch: 285\n",
      "training data:  0.004609994438022163 1.0\n",
      "epoch: 286\n",
      "training data:  0.004591195899140437 1.0\n",
      "epoch: 287\n",
      "training data:  0.004572544895436132 1.0\n",
      "epoch: 288\n",
      "training data:  0.004554039726072433 1.0\n",
      "epoch: 289\n",
      "training data:  0.004535678715977313 1.0\n",
      "epoch: 290\n",
      "training data:  0.004517460215361179 1.0\n",
      "epoch: 291\n",
      "training data:  0.004499382599245331 1.0\n",
      "epoch: 292\n",
      "training data:  0.004481444267000808 1.0\n",
      "epoch: 293\n",
      "training data:  0.004463643641897485 1.0\n",
      "epoch: 294\n",
      "training data:  0.0044459791706630124 1.0\n",
      "epoch: 295\n",
      "training data:  0.004428449323051517 1.0\n",
      "epoch: 296\n",
      "training data:  0.004411052591421693 1.0\n",
      "epoch: 297\n",
      "training data:  0.004393787490324034 1.0\n",
      "epoch: 298\n",
      "training data:  0.004376652556097123 1.0\n",
      "epoch: 299\n",
      "training data:  0.004359646346472575 1.0\n"
     ]
    }
   ],
   "source": [
    "#ejercicio6-situacion 1\n",
    "x_train = np.array([[-1,-1],[-1,1],[1,-1],[1,1]])\n",
    "y_train = np.array([[1],[-1],[-1],[1]])\n",
    "\n",
    "n = 2 #la dimension n de los datos de entrada que vamos a recorrer\n",
    "n_prime = 2 # el n prima del enunciado del 7, aca es = 2\n",
    "epocas = 300 #cantidad de epocas a realizar\n",
    "e = range(epocas)\n",
    "lr = 0.05 #learning rate\n",
    "mg = 1\n",
    "#creamos y entrenamos la red\n",
    "model = models.Network()\n",
    "model.add(layers.Dense(n_prime,activations.Tanh(),mg,n))\n",
    "model.add(layers.Dense(1,activations.Tanh(),mg))\n",
    "bs = x_train.shape[0] #batch size para stochastic gradient descendent\n",
    "loss_tr,loss_ts,acc_tr,acc_ts = model.fit(x_train,y_train,None,None,lr,epocas,bs,metrics.accuracy_xor,losses.MSE,optimizers.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c85e9c35c8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e,acc_tr) #grafico loss-epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27fe6e99e88>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e,loss_tr) #grafico acc-epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problema 6 situacion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "training data:  1.7385497948021438 0.25\n",
      "epoch: 1\n",
      "training data:  1.570649951143356 0.25\n",
      "epoch: 2\n",
      "training data:  1.3080337474620594 0.0\n",
      "epoch: 3\n",
      "training data:  1.1447962887997152 0.0\n",
      "epoch: 4\n",
      "training data:  1.099825045257141 0.0\n",
      "epoch: 5\n",
      "training data:  1.0811490244312894 0.0\n",
      "epoch: 6\n",
      "training data:  1.0712237539789997 0.0\n",
      "epoch: 7\n",
      "training data:  1.0647156080287874 0.0\n",
      "epoch: 8\n",
      "training data:  1.0596847433315846 0.0\n",
      "epoch: 9\n",
      "training data:  1.0554055397700675 0.0\n",
      "epoch: 10\n",
      "training data:  1.0515994859948445 0.0\n",
      "epoch: 11\n",
      "training data:  1.0481518586463363 0.0\n",
      "epoch: 12\n",
      "training data:  1.0450075581013432 0.0\n",
      "epoch: 13\n",
      "training data:  1.0421332207650524 0.0\n",
      "epoch: 14\n",
      "training data:  1.0395036349652311 0.0\n",
      "epoch: 15\n",
      "training data:  1.0370970119081935 0.0\n",
      "epoch: 16\n",
      "training data:  1.0348934443420246 0.0\n",
      "epoch: 17\n",
      "training data:  1.0328744727623913 0.0\n",
      "epoch: 18\n",
      "training data:  1.0310230003635807 0.0\n",
      "epoch: 19\n",
      "training data:  1.029323288208991 0.0\n",
      "epoch: 20\n",
      "training data:  1.027760944035223 0.0\n",
      "epoch: 21\n",
      "training data:  1.026322884176193 0.0\n",
      "epoch: 22\n",
      "training data:  1.0249972703658257 0.0\n",
      "epoch: 23\n",
      "training data:  1.0237734291037046 0.0\n",
      "epoch: 24\n",
      "training data:  1.0226417614181684 0.0\n",
      "epoch: 25\n",
      "training data:  1.0215936492852173 0.0\n",
      "epoch: 26\n",
      "training data:  1.0206213631530745 0.0\n",
      "epoch: 27\n",
      "training data:  1.0197179734725688 0.0\n",
      "epoch: 28\n",
      "training data:  1.018877267949599 0.0\n",
      "epoch: 29\n",
      "training data:  1.0180936753889287 0.0\n",
      "epoch: 30\n",
      "training data:  1.017362196421475 0.0\n",
      "epoch: 31\n",
      "training data:  1.0166783410321534 0.0\n",
      "epoch: 32\n",
      "training data:  1.016038072574972 0.0\n",
      "epoch: 33\n",
      "training data:  1.0154377578322378 0.0\n",
      "epoch: 34\n",
      "training data:  1.0148741226126408 0.0\n",
      "epoch: 35\n",
      "training data:  1.0143442123652715 0.0\n",
      "epoch: 36\n",
      "training data:  1.01384535729676 0.0\n",
      "epoch: 37\n",
      "training data:  1.0133751415055148 0.0\n",
      "epoch: 38\n",
      "training data:  1.012931375682778 0.0\n",
      "epoch: 39\n",
      "training data:  1.01251207296999 0.0\n",
      "epoch: 40\n",
      "training data:  1.0121154276024658 0.0\n",
      "epoch: 41\n",
      "training data:  1.0117397960087096 0.0\n",
      "epoch: 42\n",
      "training data:  1.0113836800716824 0.0\n",
      "epoch: 43\n",
      "training data:  1.011045712292359 0.0\n",
      "epoch: 44\n",
      "training data:  1.010724642626783 0.0\n",
      "epoch: 45\n",
      "training data:  1.0104193267955088 0.0\n",
      "epoch: 46\n",
      "training data:  1.0101287158889465 0.0\n",
      "epoch: 47\n",
      "training data:  1.0098518471139253 0.0\n",
      "epoch: 48\n",
      "training data:  1.00958783554595 0.0\n",
      "epoch: 49\n",
      "training data:  1.0093358667684975 0.0\n",
      "epoch: 50\n",
      "training data:  1.0090951902954173 0.0\n",
      "epoch: 51\n",
      "training data:  1.0088651136853997 0.0\n",
      "epoch: 52\n",
      "training data:  1.0086449972687315 0.0\n",
      "epoch: 53\n",
      "training data:  1.0084342494163738 0.0\n",
      "epoch: 54\n",
      "training data:  1.008232322289962 0.0\n",
      "epoch: 55\n",
      "training data:  1.008038708018801 0.0\n",
      "epoch: 56\n",
      "training data:  1.0078529352564436 0.0\n",
      "epoch: 57\n",
      "training data:  1.0076745660751287 0.0\n",
      "epoch: 58\n",
      "training data:  1.0075031931613208 0.0\n",
      "epoch: 59\n",
      "training data:  1.007338437279933 0.0\n",
      "epoch: 60\n",
      "training data:  1.0071799449786074 0.0\n",
      "epoch: 61\n",
      "training data:  1.0070273865067523 0.0\n",
      "epoch: 62\n",
      "training data:  1.0068804539269378 0.0\n",
      "epoch: 63\n",
      "training data:  1.006738859398806 0.0\n",
      "epoch: 64\n",
      "training data:  1.0066023336178944 0.0\n",
      "epoch: 65\n",
      "training data:  1.0064706243937296 0.0\n",
      "epoch: 66\n",
      "training data:  1.006343495353285 0.0\n",
      "epoch: 67\n",
      "training data:  1.0062207247574222 0.25\n",
      "epoch: 68\n",
      "training data:  1.0061021044192744 0.5\n",
      "epoch: 69\n",
      "training data:  1.0059874387147163 0.5\n",
      "epoch: 70\n",
      "training data:  1.0058765436761228 0.5\n",
      "epoch: 71\n",
      "training data:  1.005769246161526 0.75\n",
      "epoch: 72\n",
      "training data:  1.0056653830921312 0.75\n",
      "epoch: 73\n",
      "training data:  1.005564800751848 0.75\n",
      "epoch: 74\n",
      "training data:  1.0054673541431658 0.75\n",
      "epoch: 75\n",
      "training data:  1.0053729063942647 0.75\n",
      "epoch: 76\n",
      "training data:  1.0052813282127637 0.75\n",
      "epoch: 77\n",
      "training data:  1.0051924973819764 0.75\n",
      "epoch: 78\n",
      "training data:  1.0051062982959302 0.75\n",
      "epoch: 79\n",
      "training data:  1.0050226215297913 0.75\n",
      "epoch: 80\n",
      "training data:  1.00494136344264 0.75\n",
      "epoch: 81\n",
      "training data:  1.0048624258098537 0.75\n",
      "epoch: 82\n",
      "training data:  1.0047857154825894 0.75\n",
      "epoch: 83\n",
      "training data:  1.0047111440721177 0.75\n",
      "epoch: 84\n",
      "training data:  1.0046386276569474 0.75\n",
      "epoch: 85\n",
      "training data:  1.004568086510882 0.75\n",
      "epoch: 86\n",
      "training data:  1.0044994448503113 0.75\n",
      "epoch: 87\n",
      "training data:  1.0044326305991993 0.75\n",
      "epoch: 88\n",
      "training data:  1.0043675751703591 0.75\n",
      "epoch: 89\n",
      "training data:  1.004304213261741 0.75\n",
      "epoch: 90\n",
      "training data:  1.0042424826665572 0.75\n",
      "epoch: 91\n",
      "training data:  1.0041823240961887 0.75\n",
      "epoch: 92\n",
      "training data:  1.0041236810148795 0.75\n",
      "epoch: 93\n",
      "training data:  1.0040664994853474 0.75\n",
      "epoch: 94\n",
      "training data:  1.0040107280244792 0.75\n",
      "epoch: 95\n",
      "training data:  1.0039563174683637 0.75\n",
      "epoch: 96\n",
      "training data:  1.0039032208459835 0.75\n",
      "epoch: 97\n",
      "training data:  1.0038513932609219 0.75\n",
      "epoch: 98\n",
      "training data:  1.0038007917805198 0.75\n",
      "epoch: 99\n",
      "training data:  1.0037513753319376 0.75\n",
      "epoch: 100\n",
      "training data:  1.0037031046046405 0.75\n",
      "epoch: 101\n",
      "training data:  1.0036559419588496 0.75\n",
      "epoch: 102\n",
      "training data:  1.0036098513395493 0.75\n",
      "epoch: 103\n",
      "training data:  1.0035647981956626 0.75\n",
      "epoch: 104\n",
      "training data:  1.003520749404042 0.75\n",
      "epoch: 105\n",
      "training data:  1.0034776731979484 0.75\n",
      "epoch: 106\n",
      "training data:  1.0034355390997196 0.75\n",
      "epoch: 107\n",
      "training data:  1.0033943178573426 0.75\n",
      "epoch: 108\n",
      "training data:  1.0033539813846786 0.75\n",
      "epoch: 109\n",
      "training data:  1.0033145027050947 0.75\n",
      "epoch: 110\n",
      "training data:  1.003275855898284 0.75\n",
      "epoch: 111\n",
      "training data:  1.00323801605007 0.75\n",
      "epoch: 112\n",
      "training data:  1.0032009592050009 0.75\n",
      "epoch: 113\n",
      "training data:  1.003164662321558 0.75\n",
      "epoch: 114\n",
      "training data:  1.0031291032298153 0.75\n",
      "epoch: 115\n",
      "training data:  1.0030942605913942 0.75\n",
      "epoch: 116\n",
      "training data:  1.0030601138615745 0.75\n",
      "epoch: 117\n",
      "training data:  1.003026643253427 0.75\n",
      "epoch: 118\n",
      "training data:  1.0029938297038445 0.75\n",
      "epoch: 119\n",
      "training data:  1.0029616548413596 0.75\n",
      "epoch: 120\n",
      "training data:  1.0029301009556355 0.75\n",
      "epoch: 121\n",
      "training data:  1.0028991509685372 0.75\n",
      "epoch: 122\n",
      "training data:  1.0028687884066865 0.75\n",
      "epoch: 123\n",
      "training data:  1.002838997375413 0.75\n",
      "epoch: 124\n",
      "training data:  1.0028097625340202 0.75\n",
      "epoch: 125\n",
      "training data:  1.0027810690722954 0.75\n",
      "epoch: 126\n",
      "training data:  1.0027529026881825 0.75\n",
      "epoch: 127\n",
      "training data:  1.0027252495665617 0.75\n",
      "epoch: 128\n",
      "training data:  1.002698096359068 0.75\n",
      "epoch: 129\n",
      "training data:  1.002671430164889 0.75\n",
      "epoch: 130\n",
      "training data:  1.0026452385124944 0.75\n",
      "epoch: 131\n",
      "training data:  1.002619509342236 0.75\n",
      "epoch: 132\n",
      "training data:  1.0025942309897806 0.75\n",
      "epoch: 133\n",
      "training data:  1.0025693921703211 0.75\n",
      "epoch: 134\n",
      "training data:  1.0025449819635324 0.75\n",
      "epoch: 135\n",
      "training data:  1.002520989799224 0.75\n",
      "epoch: 136\n",
      "training data:  1.0024974054436575 0.75\n",
      "epoch: 137\n",
      "training data:  1.0024742189864944 0.75\n",
      "epoch: 138\n",
      "training data:  1.0024514208283342 0.75\n",
      "epoch: 139\n",
      "training data:  1.0024290016688215 0.75\n",
      "epoch: 140\n",
      "training data:  1.0024069524952852 0.75\n",
      "epoch: 141\n",
      "training data:  1.0023852645718856 0.75\n",
      "epoch: 142\n",
      "training data:  1.0023639294292424 0.75\n",
      "epoch: 143\n",
      "training data:  1.0023429388545206 0.75\n",
      "epoch: 144\n",
      "training data:  1.0023222848819489 0.75\n",
      "epoch: 145\n",
      "training data:  1.0023019597837517 0.75\n",
      "epoch: 146\n",
      "training data:  1.002281956061471 0.75\n",
      "epoch: 147\n",
      "training data:  1.0022622664376615 0.75\n",
      "epoch: 148\n",
      "training data:  1.002242883847938 0.75\n",
      "epoch: 149\n",
      "training data:  1.0022238014333638 0.75\n",
      "epoch: 150\n",
      "training data:  1.0022050125331519 0.75\n",
      "epoch: 151\n",
      "training data:  1.0021865106776782 0.75\n",
      "epoch: 152\n",
      "training data:  1.002168289581781 0.75\n",
      "epoch: 153\n",
      "training data:  1.0021503431383365 0.75\n",
      "epoch: 154\n",
      "training data:  1.0021326654121017 0.75\n",
      "epoch: 155\n",
      "training data:  1.0021152506338007 0.75\n",
      "epoch: 156\n",
      "training data:  1.002098093194461 0.75\n",
      "epoch: 157\n",
      "training data:  1.002081187639965 0.75\n",
      "epoch: 158\n",
      "training data:  1.0020645286658305 0.75\n",
      "epoch: 159\n",
      "training data:  1.0020481111121922 0.75\n",
      "epoch: 160\n",
      "training data:  1.0020319299589813 0.75\n",
      "epoch: 161\n",
      "training data:  1.0020159803213005 0.75\n",
      "epoch: 162\n",
      "training data:  1.0020002574449696 0.75\n",
      "epoch: 163\n",
      "training data:  1.001984756702253 0.75\n",
      "epoch: 164\n",
      "training data:  1.0019694735877471 0.75\n",
      "epoch: 165\n",
      "training data:  1.0019544037144248 0.75\n",
      "epoch: 166\n",
      "training data:  1.0019395428098334 0.75\n",
      "epoch: 167\n",
      "training data:  1.0019248867124355 0.75\n",
      "epoch: 168\n",
      "training data:  1.001910431368085 0.75\n",
      "epoch: 169\n",
      "training data:  1.0018961728266402 0.75\n",
      "epoch: 170\n",
      "training data:  1.0018821072386983 0.75\n",
      "epoch: 171\n",
      "training data:  1.0018682308524518 0.75\n",
      "epoch: 172\n",
      "training data:  1.0018545400106627 0.75\n",
      "epoch: 173\n",
      "training data:  1.0018410311477444 0.75\n",
      "epoch: 174\n",
      "training data:  1.0018277007869514 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175\n",
      "training data:  1.001814545537672 0.75\n",
      "epoch: 176\n",
      "training data:  1.0018015620928127 0.75\n",
      "epoch: 177\n",
      "training data:  1.0017887472262845 0.75\n",
      "epoch: 178\n",
      "training data:  1.0017760977905719 0.75\n",
      "epoch: 179\n",
      "training data:  1.0017636107143895 0.75\n",
      "epoch: 180\n",
      "training data:  1.0017512830004225 0.75\n",
      "epoch: 181\n",
      "training data:  1.0017391117231482 0.75\n",
      "epoch: 182\n",
      "training data:  1.0017270940267238 0.75\n",
      "epoch: 183\n",
      "training data:  1.0017152271229615 0.75\n",
      "epoch: 184\n",
      "training data:  1.0017035082893595 0.75\n",
      "epoch: 185\n",
      "training data:  1.0016919348672115 0.75\n",
      "epoch: 186\n",
      "training data:  1.0016805042597727 0.75\n",
      "epoch: 187\n",
      "training data:  1.0016692139304926 0.75\n",
      "epoch: 188\n",
      "training data:  1.0016580614013038 0.75\n",
      "epoch: 189\n",
      "training data:  1.0016470442509733 0.75\n",
      "epoch: 190\n",
      "training data:  1.001636160113501 0.75\n",
      "epoch: 191\n",
      "training data:  1.001625406676582 0.75\n",
      "epoch: 192\n",
      "training data:  1.0016147816801062 0.75\n",
      "epoch: 193\n",
      "training data:  1.001604282914721 0.75\n",
      "epoch: 194\n",
      "training data:  1.0015939082204297 0.75\n",
      "epoch: 195\n",
      "training data:  1.0015836554852435 0.75\n",
      "epoch: 196\n",
      "training data:  1.001573522643872 0.75\n",
      "epoch: 197\n",
      "training data:  1.0015635076764569 0.75\n",
      "epoch: 198\n",
      "training data:  1.0015536086073489 0.75\n",
      "epoch: 199\n",
      "training data:  1.0015438235039194 0.75\n",
      "epoch: 200\n",
      "training data:  1.0015341504754147 0.75\n",
      "epoch: 201\n",
      "training data:  1.0015245876718404 0.75\n",
      "epoch: 202\n",
      "training data:  1.001515133282886 0.75\n",
      "epoch: 203\n",
      "training data:  1.0015057855368819 0.75\n",
      "epoch: 204\n",
      "training data:  1.0014965426997853 0.75\n",
      "epoch: 205\n",
      "training data:  1.0014874030742023 0.75\n",
      "epoch: 206\n",
      "training data:  1.0014783649984373 0.75\n",
      "epoch: 207\n",
      "training data:  1.0014694268455726 0.75\n",
      "epoch: 208\n",
      "training data:  1.0014605870225757 0.75\n",
      "epoch: 209\n",
      "training data:  1.001451843969432 0.75\n",
      "epoch: 210\n",
      "training data:  1.001443196158307 0.75\n",
      "epoch: 211\n",
      "training data:  1.001434642092732 0.75\n",
      "epoch: 212\n",
      "training data:  1.0014261803068134 0.75\n",
      "epoch: 213\n",
      "training data:  1.0014178093644666 0.75\n",
      "epoch: 214\n",
      "training data:  1.0014095278586712 0.75\n",
      "epoch: 215\n",
      "training data:  1.0014013344107515 0.75\n",
      "epoch: 216\n",
      "training data:  1.001393227669674 0.75\n",
      "epoch: 217\n",
      "training data:  1.0013852063113673 0.75\n",
      "epoch: 218\n",
      "training data:  1.0013772690380636 0.75\n",
      "epoch: 219\n",
      "training data:  1.001369414577654 0.75\n",
      "epoch: 220\n",
      "training data:  1.00136164168307 0.75\n",
      "epoch: 221\n",
      "training data:  1.001353949131675 0.75\n",
      "epoch: 222\n",
      "training data:  1.0013463357246795 0.75\n",
      "epoch: 223\n",
      "training data:  1.001338800286567 0.75\n",
      "epoch: 224\n",
      "training data:  1.0013313416645429 0.75\n",
      "epoch: 225\n",
      "training data:  1.0013239587279927 0.75\n",
      "epoch: 226\n",
      "training data:  1.0013166503679594 0.75\n",
      "epoch: 227\n",
      "training data:  1.001309415496634 0.75\n",
      "epoch: 228\n",
      "training data:  1.0013022530468594 0.75\n",
      "epoch: 229\n",
      "training data:  1.0012951619716497 0.75\n",
      "epoch: 230\n",
      "training data:  1.0012881412437218 0.75\n",
      "epoch: 231\n",
      "training data:  1.0012811898550416 0.75\n",
      "epoch: 232\n",
      "training data:  1.0012743068163779 0.75\n",
      "epoch: 233\n",
      "training data:  1.0012674911568744 0.75\n",
      "epoch: 234\n",
      "training data:  1.00126074192363 0.75\n",
      "epoch: 235\n",
      "training data:  1.0012540581812892 0.75\n",
      "epoch: 236\n",
      "training data:  1.0012474390116486 0.75\n",
      "epoch: 237\n",
      "training data:  1.0012408835132665 0.75\n",
      "epoch: 238\n",
      "training data:  1.00123439080109 0.75\n",
      "epoch: 239\n",
      "training data:  1.0012279600060883 0.75\n",
      "epoch: 240\n",
      "training data:  1.0012215902748969 0.75\n",
      "epoch: 241\n",
      "training data:  1.0012152807694676 0.75\n",
      "epoch: 242\n",
      "training data:  1.0012090306667356 0.75\n",
      "epoch: 243\n",
      "training data:  1.0012028391582861 0.75\n",
      "epoch: 244\n",
      "training data:  1.0011967054500366 0.75\n",
      "epoch: 245\n",
      "training data:  1.0011906287619237 0.75\n",
      "epoch: 246\n",
      "training data:  1.0011846083275977 0.75\n",
      "epoch: 247\n",
      "training data:  1.0011786433941299 0.75\n",
      "epoch: 248\n",
      "training data:  1.0011727332217193 0.75\n",
      "epoch: 249\n",
      "training data:  1.001166877083415 0.75\n",
      "epoch: 250\n",
      "training data:  1.0011610742648396 0.75\n",
      "epoch: 251\n",
      "training data:  1.0011553240639233 0.75\n",
      "epoch: 252\n",
      "training data:  1.0011496257906418 0.75\n",
      "epoch: 253\n",
      "training data:  1.001143978766764 0.75\n",
      "epoch: 254\n",
      "training data:  1.0011383823256035 0.75\n",
      "epoch: 255\n",
      "training data:  1.0011328358117761 0.75\n",
      "epoch: 256\n",
      "training data:  1.001127338580966 0.75\n",
      "epoch: 257\n",
      "training data:  1.0011218899996945 0.75\n",
      "epoch: 258\n",
      "training data:  1.0011164894450975 0.75\n",
      "epoch: 259\n",
      "training data:  1.0011111363047045 0.75\n",
      "epoch: 260\n",
      "training data:  1.0011058299762277 0.75\n",
      "epoch: 261\n",
      "training data:  1.0011005698673534 0.75\n",
      "epoch: 262\n",
      "training data:  1.0010953553955366 0.75\n",
      "epoch: 263\n",
      "training data:  1.0010901859878072 0.75\n",
      "epoch: 264\n",
      "training data:  1.001085061080572 0.75\n",
      "epoch: 265\n",
      "training data:  1.0010799801194283 0.75\n",
      "epoch: 266\n",
      "training data:  1.0010749425589809 0.75\n",
      "epoch: 267\n",
      "training data:  1.0010699478626586 0.75\n",
      "epoch: 268\n",
      "training data:  1.0010649955025415 0.75\n",
      "epoch: 269\n",
      "training data:  1.0010600849591886 0.75\n",
      "epoch: 270\n",
      "training data:  1.0010552157214698 0.75\n",
      "epoch: 271\n",
      "training data:  1.0010503872864032 0.75\n",
      "epoch: 272\n",
      "training data:  1.0010455991589948 0.75\n",
      "epoch: 273\n",
      "training data:  1.0010408508520825 0.75\n",
      "epoch: 274\n",
      "training data:  1.001036141886184 0.75\n",
      "epoch: 275\n",
      "training data:  1.0010314717893474 0.75\n",
      "epoch: 276\n",
      "training data:  1.0010268400970055 0.75\n",
      "epoch: 277\n",
      "training data:  1.0010222463518357 0.75\n",
      "epoch: 278\n",
      "training data:  1.0010176901036174 0.75\n",
      "epoch: 279\n",
      "training data:  1.0010131709091001 0.75\n",
      "epoch: 280\n",
      "training data:  1.001008688331868 0.75\n",
      "epoch: 281\n",
      "training data:  1.0010042419422114 0.75\n",
      "epoch: 282\n",
      "training data:  1.0009998313169994 0.75\n",
      "epoch: 283\n",
      "training data:  1.0009954560395569 0.75\n",
      "epoch: 284\n",
      "training data:  1.0009911156995424 0.75\n",
      "epoch: 285\n",
      "training data:  1.0009868098928307 0.75\n",
      "epoch: 286\n",
      "training data:  1.0009825382213948 0.75\n",
      "epoch: 287\n",
      "training data:  1.0009783002931953 0.75\n",
      "epoch: 288\n",
      "training data:  1.0009740957220694 0.75\n",
      "epoch: 289\n",
      "training data:  1.0009699241276182 0.75\n",
      "epoch: 290\n",
      "training data:  1.000965785135108 0.75\n",
      "epoch: 291\n",
      "training data:  1.0009616783753597 0.75\n",
      "epoch: 292\n",
      "training data:  1.0009576034846521 0.75\n",
      "epoch: 293\n",
      "training data:  1.0009535601046196 0.75\n",
      "epoch: 294\n",
      "training data:  1.0009495478821577 0.75\n",
      "epoch: 295\n",
      "training data:  1.000945566469325 0.75\n",
      "epoch: 296\n",
      "training data:  1.0009416155232538 0.75\n",
      "epoch: 297\n",
      "training data:  1.000937694706055 0.75\n",
      "epoch: 298\n",
      "training data:  1.0009338036847337 0.75\n",
      "epoch: 299\n",
      "training data:  1.0009299421310975 0.75\n"
     ]
    }
   ],
   "source": [
    "mg=1\n",
    "input_layer = layers.Input(x_train.shape[1]) #input layer, la creamos para crear la concat layer despues\n",
    "layer_1 = layers.Dense(2,activations.Tanh(),mg,x_train.shape[1]) #capa 1\n",
    "layer_2 = layers.Dense(1,activations.Tanh(),mg) #creo la capa 2\n",
    "\n",
    "model = models.Network() #creo objeto tipo network\n",
    "\n",
    "model.add(layer_1) #aniado la primera capa a la red\n",
    "model.add(layers.Concat(input_layer))\n",
    "model.add(layer_2) #aniado la segunda capa a la red\n",
    "\n",
    "epocas = 300 #cantidad de epocas a realizar\n",
    "lr = 0.05 #learning rate\n",
    "bs = x_train.shape[0] #batch size para stochastic gradient descendent\n",
    "\n",
    "\n",
    "loss_tr,loss_ts,acc_tr,acc_ts = model.fit(x_train,y_train,None,None,lr,epocas,bs,metrics.accuracy_xor,losses.MSE,optimizers.SGD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

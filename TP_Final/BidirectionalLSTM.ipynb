{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler #scaling de los datos entre 0 y 1\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargo primero los datos\n",
    "file_dir = 'Datos/arg.txt'\n",
    "data = pd.read_csv(file_dir,sep=\",\",quotechar='\"',na_values=[''])\n",
    "df = pd.DataFrame(data)\n",
    "df = df.to_numpy()\n",
    "df1 = np.copy(df) #el original\n",
    "df = df[:-20] #saco los ultimos 20 dias (ult 10 para probar + ult 10 retrasados)\n",
    "df1 = df1[:-10] #saco los ultimos 10 dias retrasados\n",
    "#normalizacion\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df = scaler.fit_transform(df.reshape(-1,1))\n",
    "#split en train y test\n",
    "training_size=int(len(df)*0.8)\n",
    "test_size=len(df)-training_size\n",
    "train_data,test_data=df[0:training_size,:],df[training_size:len(df),:1] #train y test data\n",
    "lag = 3 #creo que este es el que deducen en el paper\n",
    "#creo los que vienen para la red\n",
    "x_train, y_train = create_dataset(train_data, lag)\n",
    "x_test, y_test = create_dataset(test_data, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape en (samples, time steps, features) para lstm como en pract7\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1] , 1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 234 samples, validate on 56 samples\n",
      "Epoch 1/300\n",
      " - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 2/300\n",
      " - 0s - loss: 2.6309e-04 - mse: 2.6309e-04 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 3/300\n",
      " - 0s - loss: 1.4279e-04 - mse: 1.4279e-04 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 4/300\n",
      " - 0s - loss: 1.0674e-04 - mse: 1.0674e-04 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5/300\n",
      " - 0s - loss: 5.7616e-05 - mse: 5.7616e-05 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 6/300\n",
      " - 0s - loss: 5.7785e-05 - mse: 5.7785e-05 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 7/300\n",
      " - 1s - loss: 4.4308e-05 - mse: 4.4308e-05 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 8/300\n",
      " - 1s - loss: 3.2261e-05 - mse: 3.2261e-05 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 9/300\n",
      " - 0s - loss: 2.6285e-05 - mse: 2.6285e-05 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 10/300\n",
      " - 0s - loss: 1.9467e-05 - mse: 1.9467e-05 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 11/300\n",
      " - 0s - loss: 2.5344e-05 - mse: 2.5344e-05 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 12/300\n",
      " - 0s - loss: 1.7672e-05 - mse: 1.7672e-05 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 13/300\n",
      " - 0s - loss: 1.2121e-05 - mse: 1.2121e-05 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 14/300\n",
      " - 0s - loss: 1.0400e-05 - mse: 1.0400e-05 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 15/300\n",
      " - 0s - loss: 6.8299e-06 - mse: 6.8299e-06 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 16/300\n",
      " - 0s - loss: 6.1104e-06 - mse: 6.1104e-06 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 17/300\n",
      " - 0s - loss: 3.2069e-06 - mse: 3.2069e-06 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 18/300\n",
      " - 0s - loss: 4.3071e-06 - mse: 4.3071e-06 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 19/300\n",
      " - 0s - loss: 2.6288e-06 - mse: 2.6288e-06 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 20/300\n",
      " - 0s - loss: 2.9794e-06 - mse: 2.9794e-06 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 21/300\n",
      " - 0s - loss: 2.1302e-06 - mse: 2.1302e-06 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 22/300\n",
      " - 0s - loss: 3.3932e-06 - mse: 3.3932e-06 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 23/300\n",
      " - 0s - loss: 1.6006e-06 - mse: 1.6006e-06 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 24/300\n",
      " - 0s - loss: 2.2112e-06 - mse: 2.2112e-06 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 25/300\n",
      " - 0s - loss: 2.4484e-06 - mse: 2.4484e-06 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 26/300\n",
      " - 0s - loss: 2.7080e-06 - mse: 2.7080e-06 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 27/300\n",
      " - 0s - loss: 6.7810e-06 - mse: 6.7810e-06 - val_loss: 6.1182e-04 - val_mse: 6.1182e-04\n",
      "Epoch 28/300\n",
      " - 0s - loss: 5.5978e-06 - mse: 5.5978e-06 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 29/300\n",
      " - 0s - loss: 3.0426e-06 - mse: 3.0426e-06 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 30/300\n",
      " - 1s - loss: 1.3961e-06 - mse: 1.3961e-06 - val_loss: 9.9358e-04 - val_mse: 9.9358e-04\n",
      "Epoch 31/300\n",
      " - 0s - loss: 1.8437e-06 - mse: 1.8437e-06 - val_loss: 8.9502e-04 - val_mse: 8.9502e-04\n",
      "Epoch 32/300\n",
      " - 0s - loss: 2.6471e-06 - mse: 2.6471e-06 - val_loss: 8.3457e-04 - val_mse: 8.3457e-04\n",
      "Epoch 33/300\n",
      " - 0s - loss: 2.4643e-06 - mse: 2.4643e-06 - val_loss: 7.3083e-04 - val_mse: 7.3083e-04\n",
      "Epoch 34/300\n",
      " - 0s - loss: 1.8249e-06 - mse: 1.8249e-06 - val_loss: 9.1536e-04 - val_mse: 9.1536e-04\n",
      "Epoch 35/300\n",
      " - 0s - loss: 1.3863e-06 - mse: 1.3863e-06 - val_loss: 5.5164e-04 - val_mse: 5.5164e-04\n",
      "Epoch 36/300\n",
      " - 0s - loss: 2.5248e-06 - mse: 2.5248e-06 - val_loss: 9.0775e-04 - val_mse: 9.0775e-04\n",
      "Epoch 37/300\n",
      " - 0s - loss: 1.4742e-06 - mse: 1.4742e-06 - val_loss: 7.3403e-04 - val_mse: 7.3403e-04\n",
      "Epoch 38/300\n",
      " - 0s - loss: 1.3407e-06 - mse: 1.3407e-06 - val_loss: 6.1838e-04 - val_mse: 6.1838e-04\n",
      "Epoch 39/300\n",
      " - 0s - loss: 1.7622e-06 - mse: 1.7622e-06 - val_loss: 6.5154e-04 - val_mse: 6.5154e-04\n",
      "Epoch 40/300\n",
      " - 0s - loss: 1.8939e-06 - mse: 1.8939e-06 - val_loss: 7.4131e-04 - val_mse: 7.4131e-04\n",
      "Epoch 41/300\n",
      " - 0s - loss: 3.4332e-06 - mse: 3.4332e-06 - val_loss: 4.8051e-04 - val_mse: 4.8051e-04\n",
      "Epoch 42/300\n",
      " - 0s - loss: 2.5664e-06 - mse: 2.5664e-06 - val_loss: 5.1959e-04 - val_mse: 5.1959e-04\n",
      "Epoch 43/300\n",
      " - 0s - loss: 3.5483e-06 - mse: 3.5483e-06 - val_loss: 4.2073e-04 - val_mse: 4.2073e-04\n",
      "Epoch 44/300\n",
      " - 0s - loss: 4.1792e-06 - mse: 4.1792e-06 - val_loss: 4.7205e-04 - val_mse: 4.7205e-04\n",
      "Epoch 45/300\n",
      " - 0s - loss: 1.9671e-06 - mse: 1.9671e-06 - val_loss: 4.7222e-04 - val_mse: 4.7222e-04\n",
      "Epoch 46/300\n",
      " - 0s - loss: 1.8487e-06 - mse: 1.8487e-06 - val_loss: 5.1719e-04 - val_mse: 5.1719e-04\n",
      "Epoch 47/300\n",
      " - 0s - loss: 3.4523e-06 - mse: 3.4523e-06 - val_loss: 4.4445e-04 - val_mse: 4.4445e-04\n",
      "Epoch 48/300\n",
      " - 0s - loss: 2.0965e-06 - mse: 2.0965e-06 - val_loss: 5.1480e-04 - val_mse: 5.1480e-04\n",
      "Epoch 49/300\n",
      " - 0s - loss: 2.8420e-06 - mse: 2.8420e-06 - val_loss: 6.9396e-04 - val_mse: 6.9396e-04\n",
      "Epoch 50/300\n",
      " - 0s - loss: 2.4251e-06 - mse: 2.4251e-06 - val_loss: 7.7217e-04 - val_mse: 7.7217e-04\n",
      "Epoch 51/300\n",
      " - 0s - loss: 2.5348e-06 - mse: 2.5348e-06 - val_loss: 4.4731e-04 - val_mse: 4.4731e-04\n",
      "Epoch 52/300\n",
      " - 0s - loss: 3.5915e-06 - mse: 3.5915e-06 - val_loss: 5.0628e-04 - val_mse: 5.0628e-04\n",
      "Epoch 53/300\n",
      " - 0s - loss: 4.4878e-06 - mse: 4.4878e-06 - val_loss: 8.0740e-04 - val_mse: 8.0740e-04\n",
      "Epoch 54/300\n",
      " - 0s - loss: 2.9259e-06 - mse: 2.9259e-06 - val_loss: 5.4258e-04 - val_mse: 5.4258e-04\n",
      "Epoch 55/300\n",
      " - 0s - loss: 2.1342e-06 - mse: 2.1342e-06 - val_loss: 2.1898e-04 - val_mse: 2.1898e-04\n",
      "Epoch 56/300\n",
      " - 0s - loss: 8.9051e-06 - mse: 8.9051e-06 - val_loss: 5.2176e-04 - val_mse: 5.2176e-04\n",
      "Epoch 57/300\n",
      " - 0s - loss: 8.6333e-06 - mse: 8.6333e-06 - val_loss: 4.5050e-04 - val_mse: 4.5050e-04\n",
      "Epoch 58/300\n",
      " - 0s - loss: 6.8610e-06 - mse: 6.8610e-06 - val_loss: 5.3922e-04 - val_mse: 5.3922e-04\n",
      "Epoch 59/300\n",
      " - 0s - loss: 3.6564e-06 - mse: 3.6564e-06 - val_loss: 3.6731e-04 - val_mse: 3.6731e-04\n",
      "Epoch 60/300\n",
      " - 0s - loss: 3.0879e-06 - mse: 3.0879e-06 - val_loss: 2.9878e-04 - val_mse: 2.9878e-04\n",
      "Epoch 61/300\n",
      " - 0s - loss: 1.0358e-05 - mse: 1.0358e-05 - val_loss: 5.5359e-04 - val_mse: 5.5359e-04\n",
      "Epoch 62/300\n",
      " - 0s - loss: 1.1015e-05 - mse: 1.1015e-05 - val_loss: 3.4615e-05 - val_mse: 3.4615e-05\n",
      "Epoch 63/300\n",
      " - 0s - loss: 9.3426e-06 - mse: 9.3426e-06 - val_loss: 9.1334e-05 - val_mse: 9.1334e-05\n",
      "Epoch 64/300\n",
      " - 1s - loss: 5.7228e-06 - mse: 5.7228e-06 - val_loss: 1.9923e-04 - val_mse: 1.9923e-04\n",
      "Epoch 65/300\n",
      " - 0s - loss: 7.2562e-06 - mse: 7.2562e-06 - val_loss: 2.8230e-04 - val_mse: 2.8230e-04\n",
      "Epoch 66/300\n",
      " - 0s - loss: 8.0001e-06 - mse: 8.0001e-06 - val_loss: 7.9535e-04 - val_mse: 7.9535e-04\n",
      "Epoch 67/300\n",
      " - 0s - loss: 4.6173e-06 - mse: 4.6173e-06 - val_loss: 1.1864e-04 - val_mse: 1.1864e-04\n",
      "Epoch 68/300\n",
      " - 0s - loss: 3.8135e-06 - mse: 3.8135e-06 - val_loss: 4.4160e-04 - val_mse: 4.4160e-04\n",
      "Epoch 69/300\n",
      " - 0s - loss: 3.7263e-06 - mse: 3.7263e-06 - val_loss: 3.7195e-04 - val_mse: 3.7195e-04\n",
      "Epoch 70/300\n",
      " - 0s - loss: 3.4646e-06 - mse: 3.4646e-06 - val_loss: 3.8596e-04 - val_mse: 3.8596e-04\n",
      "Epoch 71/300\n",
      " - 0s - loss: 6.2143e-06 - mse: 6.2143e-06 - val_loss: 1.1369e-04 - val_mse: 1.1369e-04\n",
      "Epoch 72/300\n",
      " - 0s - loss: 1.1536e-05 - mse: 1.1536e-05 - val_loss: 4.4166e-04 - val_mse: 4.4166e-04\n",
      "Epoch 73/300\n",
      " - 0s - loss: 1.0672e-05 - mse: 1.0672e-05 - val_loss: 3.9396e-04 - val_mse: 3.9396e-04\n",
      "Epoch 74/300\n",
      " - 0s - loss: 1.6856e-05 - mse: 1.6856e-05 - val_loss: 5.8461e-04 - val_mse: 5.8461e-04\n",
      "Epoch 75/300\n",
      " - 0s - loss: 5.8887e-06 - mse: 5.8887e-06 - val_loss: 4.7760e-04 - val_mse: 4.7760e-04\n",
      "Epoch 76/300\n",
      " - 0s - loss: 6.0265e-06 - mse: 6.0265e-06 - val_loss: 1.4190e-04 - val_mse: 1.4190e-04\n",
      "Epoch 77/300\n",
      " - 0s - loss: 1.9930e-06 - mse: 1.9930e-06 - val_loss: 1.6234e-04 - val_mse: 1.6234e-04\n",
      "Epoch 78/300\n",
      " - 0s - loss: 8.7340e-06 - mse: 8.7340e-06 - val_loss: 4.1724e-05 - val_mse: 4.1724e-05\n",
      "Epoch 79/300\n",
      " - 0s - loss: 5.2711e-06 - mse: 5.2711e-06 - val_loss: 3.9348e-05 - val_mse: 3.9348e-05\n",
      "Epoch 80/300\n",
      " - 0s - loss: 5.5339e-06 - mse: 5.5339e-06 - val_loss: 2.7037e-04 - val_mse: 2.7037e-04\n",
      "Epoch 81/300\n",
      " - 0s - loss: 2.6699e-06 - mse: 2.6699e-06 - val_loss: 1.9758e-04 - val_mse: 1.9758e-04\n",
      "Epoch 82/300\n",
      " - 0s - loss: 1.0249e-05 - mse: 1.0249e-05 - val_loss: 3.1242e-04 - val_mse: 3.1242e-04\n",
      "Epoch 83/300\n",
      " - 0s - loss: 9.6665e-06 - mse: 9.6665e-06 - val_loss: 4.8374e-05 - val_mse: 4.8374e-05\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 7.8645e-06 - mse: 7.8645e-06 - val_loss: 1.7584e-04 - val_mse: 1.7584e-04\n",
      "Epoch 85/300\n",
      " - 0s - loss: 5.0316e-06 - mse: 5.0316e-06 - val_loss: 3.2582e-05 - val_mse: 3.2582e-05\n",
      "Epoch 86/300\n",
      " - 0s - loss: 4.8841e-06 - mse: 4.8841e-06 - val_loss: 9.9180e-05 - val_mse: 9.9180e-05\n",
      "Epoch 87/300\n",
      " - 0s - loss: 7.8543e-06 - mse: 7.8543e-06 - val_loss: 1.4769e-05 - val_mse: 1.4769e-05\n",
      "Epoch 88/300\n",
      " - 0s - loss: 1.0255e-05 - mse: 1.0255e-05 - val_loss: 1.8837e-05 - val_mse: 1.8837e-05\n",
      "Epoch 89/300\n",
      " - 0s - loss: 5.0120e-06 - mse: 5.0120e-06 - val_loss: 1.3287e-05 - val_mse: 1.3287e-05\n",
      "Epoch 90/300\n",
      " - 0s - loss: 2.7297e-06 - mse: 2.7297e-06 - val_loss: 8.4033e-05 - val_mse: 8.4033e-05\n",
      "Epoch 91/300\n",
      " - 0s - loss: 6.3028e-06 - mse: 6.3028e-06 - val_loss: 5.8184e-05 - val_mse: 5.8184e-05\n",
      "Epoch 92/300\n",
      " - 0s - loss: 4.1816e-06 - mse: 4.1816e-06 - val_loss: 8.7688e-06 - val_mse: 8.7688e-06\n",
      "Epoch 93/300\n",
      " - 0s - loss: 2.7436e-06 - mse: 2.7436e-06 - val_loss: 2.9606e-05 - val_mse: 2.9606e-05\n",
      "Epoch 94/300\n",
      " - 0s - loss: 3.8858e-06 - mse: 3.8858e-06 - val_loss: 3.3244e-05 - val_mse: 3.3244e-05\n",
      "Epoch 95/300\n",
      " - 0s - loss: 4.1753e-06 - mse: 4.1753e-06 - val_loss: 2.5599e-05 - val_mse: 2.5599e-05\n",
      "Epoch 96/300\n",
      " - 0s - loss: 2.8746e-06 - mse: 2.8746e-06 - val_loss: 1.3101e-04 - val_mse: 1.3101e-04\n",
      "Epoch 97/300\n",
      " - 0s - loss: 4.6186e-06 - mse: 4.6186e-06 - val_loss: 1.4530e-05 - val_mse: 1.4530e-05\n",
      "Epoch 98/300\n",
      " - 0s - loss: 1.0703e-05 - mse: 1.0703e-05 - val_loss: 3.1712e-05 - val_mse: 3.1712e-05\n",
      "Epoch 99/300\n",
      " - 0s - loss: 8.2353e-06 - mse: 8.2353e-06 - val_loss: 2.7825e-05 - val_mse: 2.7825e-05\n",
      "Epoch 100/300\n",
      " - 0s - loss: 4.2692e-06 - mse: 4.2692e-06 - val_loss: 2.4904e-04 - val_mse: 2.4904e-04\n",
      "Epoch 101/300\n",
      " - 0s - loss: 4.5213e-06 - mse: 4.5213e-06 - val_loss: 1.5090e-05 - val_mse: 1.5090e-05\n",
      "Epoch 102/300\n",
      " - 0s - loss: 3.4627e-06 - mse: 3.4627e-06 - val_loss: 8.3384e-05 - val_mse: 8.3384e-05\n",
      "Epoch 103/300\n",
      " - 0s - loss: 2.9414e-06 - mse: 2.9414e-06 - val_loss: 6.7329e-05 - val_mse: 6.7329e-05\n",
      "Epoch 104/300\n",
      " - 0s - loss: 6.5276e-06 - mse: 6.5276e-06 - val_loss: 7.8386e-05 - val_mse: 7.8386e-05\n",
      "Epoch 105/300\n",
      " - 0s - loss: 1.3648e-05 - mse: 1.3648e-05 - val_loss: 1.2244e-04 - val_mse: 1.2244e-04\n",
      "Epoch 106/300\n",
      " - 0s - loss: 3.8124e-06 - mse: 3.8124e-06 - val_loss: 1.9059e-05 - val_mse: 1.9059e-05\n",
      "Epoch 107/300\n",
      " - 0s - loss: 1.3202e-05 - mse: 1.3202e-05 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 108/300\n",
      " - 0s - loss: 1.0810e-05 - mse: 1.0810e-05 - val_loss: 3.5098e-05 - val_mse: 3.5098e-05\n",
      "Epoch 109/300\n",
      " - 0s - loss: 6.4064e-06 - mse: 6.4064e-06 - val_loss: 3.8848e-05 - val_mse: 3.8848e-05\n",
      "Epoch 110/300\n",
      " - 0s - loss: 5.3289e-06 - mse: 5.3289e-06 - val_loss: 1.7419e-04 - val_mse: 1.7419e-04\n",
      "Epoch 111/300\n",
      " - 0s - loss: 7.9150e-06 - mse: 7.9150e-06 - val_loss: 1.2735e-04 - val_mse: 1.2735e-04\n",
      "Epoch 112/300\n",
      " - 0s - loss: 6.1693e-06 - mse: 6.1694e-06 - val_loss: 2.2654e-05 - val_mse: 2.2654e-05\n",
      "Epoch 113/300\n",
      " - 0s - loss: 7.1558e-06 - mse: 7.1558e-06 - val_loss: 4.5876e-05 - val_mse: 4.5876e-05\n",
      "Epoch 114/300\n",
      " - 0s - loss: 3.1645e-06 - mse: 3.1645e-06 - val_loss: 3.2178e-04 - val_mse: 3.2178e-04\n",
      "Epoch 115/300\n",
      " - 0s - loss: 2.3475e-06 - mse: 2.3475e-06 - val_loss: 4.5254e-05 - val_mse: 4.5254e-05\n",
      "Epoch 116/300\n",
      " - 0s - loss: 2.1104e-06 - mse: 2.1104e-06 - val_loss: 2.9330e-05 - val_mse: 2.9330e-05\n",
      "Epoch 117/300\n",
      " - 0s - loss: 2.4776e-06 - mse: 2.4776e-06 - val_loss: 4.9868e-04 - val_mse: 4.9868e-04\n",
      "Epoch 118/300\n",
      " - 0s - loss: 2.7547e-06 - mse: 2.7547e-06 - val_loss: 4.4147e-04 - val_mse: 4.4147e-04\n",
      "Epoch 119/300\n",
      " - 0s - loss: 4.5246e-06 - mse: 4.5246e-06 - val_loss: 4.7200e-05 - val_mse: 4.7200e-05\n",
      "Epoch 120/300\n",
      " - 0s - loss: 3.7581e-06 - mse: 3.7581e-06 - val_loss: 1.4170e-04 - val_mse: 1.4170e-04\n",
      "Epoch 121/300\n",
      " - 0s - loss: 6.2806e-06 - mse: 6.2806e-06 - val_loss: 9.0963e-05 - val_mse: 9.0963e-05\n",
      "Epoch 122/300\n",
      " - 0s - loss: 1.5225e-05 - mse: 1.5225e-05 - val_loss: 5.6111e-05 - val_mse: 5.6111e-05\n",
      "Epoch 123/300\n",
      " - 0s - loss: 2.2240e-05 - mse: 2.2240e-05 - val_loss: 8.2876e-05 - val_mse: 8.2876e-05\n",
      "Epoch 124/300\n",
      " - 0s - loss: 2.0045e-05 - mse: 2.0045e-05 - val_loss: 5.0131e-04 - val_mse: 5.0131e-04\n",
      "Epoch 125/300\n",
      " - 0s - loss: 4.8081e-06 - mse: 4.8081e-06 - val_loss: 9.9233e-05 - val_mse: 9.9233e-05\n",
      "Epoch 126/300\n",
      " - 0s - loss: 3.4616e-06 - mse: 3.4616e-06 - val_loss: 2.0418e-04 - val_mse: 2.0418e-04\n",
      "Epoch 127/300\n",
      " - 0s - loss: 2.4518e-06 - mse: 2.4518e-06 - val_loss: 2.4605e-04 - val_mse: 2.4605e-04\n",
      "Epoch 128/300\n",
      " - 0s - loss: 4.0295e-06 - mse: 4.0295e-06 - val_loss: 1.7564e-04 - val_mse: 1.7564e-04\n",
      "Epoch 129/300\n",
      " - 0s - loss: 6.6949e-06 - mse: 6.6949e-06 - val_loss: 1.3365e-04 - val_mse: 1.3365e-04\n",
      "Epoch 130/300\n",
      " - 0s - loss: 3.7064e-06 - mse: 3.7064e-06 - val_loss: 1.9499e-04 - val_mse: 1.9499e-04\n",
      "Epoch 131/300\n",
      " - 0s - loss: 2.2415e-06 - mse: 2.2415e-06 - val_loss: 4.2575e-04 - val_mse: 4.2575e-04\n",
      "Epoch 132/300\n",
      " - 0s - loss: 2.4872e-06 - mse: 2.4872e-06 - val_loss: 9.0660e-05 - val_mse: 9.0660e-05\n",
      "Epoch 133/300\n",
      " - 0s - loss: 3.1025e-06 - mse: 3.1025e-06 - val_loss: 3.8059e-04 - val_mse: 3.8059e-04\n",
      "Epoch 134/300\n",
      " - 0s - loss: 2.8332e-06 - mse: 2.8332e-06 - val_loss: 2.8756e-04 - val_mse: 2.8756e-04\n",
      "Epoch 135/300\n",
      " - 0s - loss: 2.7099e-06 - mse: 2.7099e-06 - val_loss: 2.4332e-04 - val_mse: 2.4332e-04\n",
      "Epoch 136/300\n",
      " - 0s - loss: 3.5221e-06 - mse: 3.5221e-06 - val_loss: 8.6664e-05 - val_mse: 8.6664e-05\n",
      "Epoch 137/300\n",
      " - 0s - loss: 9.4510e-06 - mse: 9.4510e-06 - val_loss: 1.0379e-04 - val_mse: 1.0379e-04\n",
      "Epoch 138/300\n",
      " - 0s - loss: 6.1264e-06 - mse: 6.1264e-06 - val_loss: 7.0193e-04 - val_mse: 7.0193e-04\n",
      "Epoch 139/300\n",
      " - 0s - loss: 4.9393e-06 - mse: 4.9393e-06 - val_loss: 8.9512e-05 - val_mse: 8.9512e-05\n",
      "Epoch 140/300\n",
      " - 0s - loss: 4.7963e-06 - mse: 4.7963e-06 - val_loss: 5.3805e-04 - val_mse: 5.3805e-04\n",
      "Epoch 141/300\n",
      " - 0s - loss: 2.4390e-06 - mse: 2.4390e-06 - val_loss: 2.5942e-04 - val_mse: 2.5942e-04\n",
      "Epoch 142/300\n",
      " - 0s - loss: 1.4719e-06 - mse: 1.4719e-06 - val_loss: 2.9521e-04 - val_mse: 2.9521e-04\n",
      "Epoch 143/300\n",
      " - 0s - loss: 2.6333e-06 - mse: 2.6333e-06 - val_loss: 4.1267e-04 - val_mse: 4.1267e-04\n",
      "Epoch 144/300\n",
      " - 0s - loss: 3.5787e-06 - mse: 3.5787e-06 - val_loss: 5.3818e-04 - val_mse: 5.3818e-04\n",
      "Epoch 145/300\n",
      " - 0s - loss: 2.7962e-06 - mse: 2.7962e-06 - val_loss: 4.7404e-04 - val_mse: 4.7404e-04\n",
      "Epoch 146/300\n",
      " - 0s - loss: 2.6855e-06 - mse: 2.6855e-06 - val_loss: 4.2001e-04 - val_mse: 4.2001e-04\n",
      "Epoch 147/300\n",
      " - 0s - loss: 1.9078e-06 - mse: 1.9078e-06 - val_loss: 3.7584e-04 - val_mse: 3.7584e-04\n",
      "Epoch 148/300\n",
      " - 0s - loss: 2.7000e-06 - mse: 2.7000e-06 - val_loss: 4.0500e-04 - val_mse: 4.0500e-04\n",
      "Epoch 149/300\n",
      " - 0s - loss: 4.9086e-06 - mse: 4.9086e-06 - val_loss: 2.2483e-04 - val_mse: 2.2483e-04\n",
      "Epoch 150/300\n",
      " - 0s - loss: 2.3222e-06 - mse: 2.3222e-06 - val_loss: 3.4585e-04 - val_mse: 3.4585e-04\n",
      "Epoch 151/300\n",
      " - 0s - loss: 1.6561e-06 - mse: 1.6561e-06 - val_loss: 2.8090e-04 - val_mse: 2.8090e-04\n",
      "Epoch 152/300\n",
      " - 0s - loss: 3.6894e-06 - mse: 3.6894e-06 - val_loss: 4.6079e-04 - val_mse: 4.6079e-04\n",
      "Epoch 153/300\n",
      " - 0s - loss: 3.2079e-06 - mse: 3.2079e-06 - val_loss: 2.3366e-04 - val_mse: 2.3366e-04\n",
      "Epoch 154/300\n",
      " - 0s - loss: 3.6477e-06 - mse: 3.6477e-06 - val_loss: 5.7137e-04 - val_mse: 5.7137e-04\n",
      "Epoch 155/300\n",
      " - 0s - loss: 2.2652e-06 - mse: 2.2652e-06 - val_loss: 4.5161e-04 - val_mse: 4.5161e-04\n",
      "Epoch 156/300\n",
      " - 0s - loss: 3.0241e-06 - mse: 3.0241e-06 - val_loss: 3.7882e-04 - val_mse: 3.7882e-04\n",
      "Epoch 157/300\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=100,activation='relu',input_shape=(lag,1),recurrent_dropout=0.5)))\n",
    "model.add(keras.layers.Dense(units=1))\n",
    "model.compile(optimizer='adam',loss=keras.losses.MSE,metrics=['mse']) #metrics=['mean_absolute_percentage_error']\n",
    "history = model.fit(x_train, y_train,epochs=300,validation_data=(x_test,y_test),batch_size=4,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=model.predict(x_train)\n",
    "test_predict=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train mse squared:',np.sqrt(mean_squared_error(y_train,train_predict))) \n",
    "print('test mse squared:',np.sqrt(mean_squared_error(y_test,test_predict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictPlot = np.empty_like(df)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[lag:len(train_predict)+lag, :] = train_predict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(df)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict)+(lag*2)+1:len(df)-1, :] = test_predict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(df))\n",
    "plt.plot(trainPredictPlot,label='train')\n",
    "plt.plot(testPredictPlot,label='test')\n",
    "plt.grid()\n",
    "plt.title('Argentina')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(test_data)\n",
    "x_input=test_data[n-lag:].reshape(1,-1)\n",
    "temp_input=list(x_input)\n",
    "temp_input=temp_input[0].tolist()\n",
    "lst_output=[]\n",
    "n_steps=lag\n",
    "i=0\n",
    "\n",
    "while(i<10): \n",
    "    if(len(temp_input)>lag):\n",
    "        #print(temp_input)\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        x_input=x_input.reshape(1,-1)\n",
    "        x_input = x_input.reshape((1, lag, 1))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, lag,1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df1)\n",
    "days = np.arange(len(df1))\n",
    "dias_forecast = days[-10:]\n",
    "plt.plot(dias_forecast,scaler.inverse_transform(lst_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
